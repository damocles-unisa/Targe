{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, BitsAndBytesConfig\n",
    "from lm_eval.api.instance import Instance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categories_dict = {\n",
    "     'Smart Devices':                                  1,\n",
    "     'Wearable devices':                               2,\n",
    "     'Time & location':                                3,\n",
    "     'Online services':                                4,\n",
    "     'Personal data managers and schedulers':          5,\n",
    "     'Iot Hubs/Integration solutions':                 6,\n",
    "     'Automobiles':                                    7,\n",
    "     'Social networking, blogging, sharing platforms': 8,\n",
    "     'Cloud storage':                                  9,\n",
    "     'Messaging, team collaboration, VoIP':            10,\n",
    "     'Smartphone applications':                        11,\n",
    "     'RSS and recommendation systems':                 12,\n",
    "     'Mail services':                                  13,\n",
    "     'Other':                                          14,\n",
    "}"
   ],
   "id": "fbfb443ff835b857",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TextCategoryModel(nn.Module):\n",
    "    def __init__(self, num_categories, hidden_dim=128, text_embedding_dim=384):\n",
    "        super(TextCategoryModel, self).__init__()\n",
    "        self.text_embedding_dim = text_embedding_dim  # From all-MiniLM-L6-v2\n",
    "        self.fc_text = nn.Linear(self.text_embedding_dim, hidden_dim)  # From 384 to hidden_dim\n",
    "        self.fc_combined = nn.Linear(hidden_dim, hidden_dim)  # Keep the same dimension for next layer\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_categories)  # Output layer for multi-class\n",
    "\n",
    "    def forward(self, text_embedding):\n",
    "        # Pass through text embedding layer\n",
    "        text_out = F.relu(self.fc_text(text_embedding))\n",
    "        combined_out = F.relu(self.fc_combined(text_out))  # Apply ReLU activation after combining\n",
    "        output = self.output_layer(combined_out)  # Logits for multi-class\n",
    "        return output\n",
    "    \n",
    "def get_text_embedding(text, sentence_model):\n",
    "    # Get text embeddings from the sentence transformer\n",
    "    #try:\n",
    "    embedding = sentence_model.encode(text, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
    "    #except:\n",
    "    #embedding = sentence_model.encode(text, convert_to_tensor=True, device=device)\n",
    "    return embedding\n",
    "\n",
    "def classify_text(text, category_classifier, sentence_model):\n",
    "    # Get text embedding\n",
    "    text_embedding = get_text_embedding(text, sentence_model)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = category_classifier(text_embedding.unsqueeze(0).to(device))  # Add batch dimension\n",
    "        predicted_class = torch.argmax(outputs, dim=1).item()  # Get the index of the predicted class\n",
    "\n",
    "    return predicted_class + 1\n",
    "\n",
    "def predict_joint_probability(sub_dialogue, model, tokenizer):\n",
    "    input_ids = tokenizer(sub_dialogue, return_tensors=\"pt\").input_ids.to(device)\n",
    "        \n",
    "    # Create an Instance object\n",
    "    instance = Instance(request_type=\"loglikelihood_rolling\", doc={}, arguments=(sub_dialogue,), idx=0)\n",
    "    \n",
    "    # Compute the loglikelihood\n",
    "    log_likelihood = model.loglikelihood_rolling([instance], True)[0]\n",
    "\n",
    "    return log_likelihood, input_ids.size(1)\n",
    "\n",
    "def predict_probability_perplexity(log_likelihood, num_token):\n",
    "    return math.exp(-log_likelihood / num_token)\n",
    "\n",
    "def compute_perplexity(text, model, tokenizer):\n",
    "    log_likelihood, num_token = predict_joint_probability(text, model, tokenizer)\n",
    "    perplexity = predict_probability_perplexity(log_likelihood, num_token)\n",
    "    \n",
    "    return perplexity, log_likelihood, num_token\n",
    "\n",
    "def get_function(services, functions):\n",
    "    results = {}\n",
    "    for i in range(len(services)):\n",
    "        service = services[i][1]\n",
    "        if service in functions:\n",
    "            results[service] = functions[service]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_combinations(triggers, actions):\n",
    "    for trigger_service, trigger_functions in triggers.items():\n",
    "        for trigger_function in trigger_functions:\n",
    "            for action_service, action_functions in actions.items():\n",
    "                for action_function in action_functions:\n",
    "                    yield str('IF ' + trigger_service) + ' ' + str(trigger_function) + ' THEN ' + str(action_service) + ' ' + str(action_function)\n",
    "\n",
    "def compute_mrr(list, match, k):\n",
    "    for i in range(min(k, len(list))): \n",
    "        if list[i][1] == match:\n",
    "            return 1 / (i + 1)\n",
    "    return 0"
   ],
   "id": "59225998a5d42cc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_model(adapter_model_id='adapter/recipe_adapter'):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('LLM NAME')\n",
    "    quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path='LLM NAME',\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    tapir_model = PeftModel.from_pretrained(model, model_id=adapter_model_id, is_trainable=True)\n",
    "\n",
    "    print(tapir_model.print_trainable_parameters())\n",
    "\n",
    "    return tapir_model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model('adapter_name')\n",
    "\n",
    "def topk_service(text, list, sentence_model, k):\n",
    "    scored = []\n",
    "\n",
    "    service_embeddings = get_text_embedding(list, sentence_model)\n",
    "    text_embedding = get_text_embedding(text, sentence_model)\n",
    "\n",
    "    for i in range(len(list)):\n",
    "        score = sentence_model.similarity(text_embedding, service_embeddings[i])\n",
    "        scored.append((score.item(), list[i]))\n",
    "    scored.sort(reverse=True)\n",
    "\n",
    "    return scored[:k]\n",
    "\n",
    "def get_topk_recipe(generated, combinations, trigger_embedder, action_embedder, k):\n",
    "    scored = []\n",
    "    try:\n",
    "        trigger_generated = generated.split('THEN', 1)[0].strip()\n",
    "        action_generated = 'THEN' + generated.split('THEN', 1)[1].strip()\n",
    "    except:\n",
    "        return scored\n",
    "\n",
    "    trigger_generated_embedding = get_text_embedding(trigger_generated, trigger_embedder)\n",
    "    action_generated_embedding = get_text_embedding(action_generated, action_embedder)\n",
    "\n",
    "    trigger_combinations = []\n",
    "    action_combinations = []\n",
    "    temp_combination = []\n",
    "    for combination in combinations:\n",
    "        trigger_combinations.append(combination.split('THEN', 1)[0].strip())\n",
    "        action_combinations.append('THEN' + combination.split('THEN', 1)[1].strip())\n",
    "        temp_combination.append(combination)\n",
    "\n",
    "    trigger_embeddings = get_text_embedding(trigger_combinations, trigger_embedder)\n",
    "    action_embeddings = get_text_embedding(action_combinations, action_embedder)\n",
    "\n",
    "    i = 0\n",
    "    for combination in temp_combination:\n",
    "        score_trigger = trigger_embedder.similarity(trigger_generated_embedding, trigger_embeddings[i]).item()\n",
    "        score_action = action_embedder.similarity(action_generated_embedding, action_embeddings[i]).item()\n",
    "        scored.append(compute_perplexity(combination, model, tokenizer) / score_trigger.item() * score_action.item(), combination)\n",
    "        #scored.append((score_trigger * score_action, combination))\n",
    "        i+=1\n",
    "    scored.sort(reverse=True)\n",
    "    return scored[:k]"
   ],
   "id": "df77c972e85da23b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Load generated test set\n",
    "gold_generated_crg_set = pd.read_csv('../../data/generated/generated_recipe_gold.csv')\n",
    "noisy_generated_crg_set = pd.read_csv('../../data/generated/generated_recipe_noisy.csv')\n",
    "\n",
    "gold_generated_icg_trigger_set = pd.read_csv('../../data/generated/generated_trigger_gold.csv')\n",
    "noisy_generated_icg_trigger_set = pd.read_csv('../../data/generated/generated_trigger_noisy.csv')\n",
    "\n",
    "gold_generated_icg_action_set = pd.read_csv('../../data/generated/generated_action_gold.csv')\n",
    "noisy_generated_icg_action_set = pd.read_csv('../../data/generated/generated_action_noisy.csv')\n",
    "\n",
    "# Service list\n",
    "action_services = pd.read_csv(f\"../../data/services/action_services.csv\")\n",
    "trigger_services = pd.read_csv(f\"../../data/services/trigger_services.csv\")\n",
    "\n",
    "# Functionality list\n",
    "with open(\"../../data/services/action_functions.json\") as json_file:\n",
    "    action_functions = json.load(json_file)\n",
    "\n",
    "with open(\"../../data/services/trigger_functions.json\") as json_file:\n",
    "    trigger_functions = json.load(json_file)"
   ],
   "id": "b35c979084c31906",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "name = 'ModernBERT-base-msmarco'\n",
    "target = 'default'\n",
    "\n",
    "if target == 'default':\n",
    "    action_embedder = SentenceTransformer(f'joe32140/{name}').to(device)\n",
    "    trigger_embedder = SentenceTransformer(f'joe32140/{name}').to(device)\n",
    "else:\n",
    "    action_embedder = SentenceTransformer(f'../../models/{name}/action_{target}_{name}_embedder').to(device)\n",
    "    trigger_embedder = SentenceTransformer(f'../../models/{name}/trigger_{target}_{name}_embedder').to(device)\n",
    "\n",
    "num_categories = 14\n",
    "trigger_classifier = TextCategoryModel(num_categories,text_embedding_dim=trigger_embedder.get_sentence_embedding_dimension()).to(device)\n",
    "action_classifier = TextCategoryModel(num_categories,text_embedding_dim=action_embedder.get_sentence_embedding_dimension()).to(device)\n",
    "\n",
    "trigger_classifier.load_state_dict(torch.load(f'../../models/{name}/trigger_{target}_classifier/trigger_classifier.pth'))\n",
    "action_classifier.load_state_dict(torch.load(f'../../models/{name}/action_{target}_classifier/action_classifier.pth'))"
   ],
   "id": "1f9598eb708c9379",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.set_float32_matmul_precision('high')",
   "id": "42a145ad0830f6c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_df = pd.DataFrame(columns=['top','output'])\n",
    "\n",
    "exact_match = 0\n",
    "mrr_3 = 0.0\n",
    "mrr_5 = 0.0\n",
    "verbose = False\n",
    "pbar =  tqdm.tqdm(noisy_generated_crg_set.iterrows(), total=len(noisy_generated_crg_set), desc=\"Processing Rows\")\n",
    "\n",
    "for i, row in pbar:\n",
    "    # Skip when LLM match to speed up evaluation\n",
    "    if row['generated'] == row['output']:\n",
    "        temp_df = pd.DataFrame({'top': [row['generated']], 'output': [row['output']]})\n",
    "        output_df = pd.concat([output_df, temp_df], ignore_index=True)\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        trigger, action = row['generated'].split('THEN', 1)\n",
    "        trigger = trigger.replace('IF','').strip()\n",
    "        action = action.strip()\n",
    "    except:\n",
    "        trigger = row['generated']\n",
    "        action = row['generated']\n",
    "        \n",
    "    trigger_class = classify_text(trigger, trigger_classifier, trigger_embedder)\n",
    "    action_class = classify_text(action, action_classifier, action_embedder)\n",
    "    \n",
    "    trigger_list = trigger_services[trigger_services['category'] == trigger_class]\n",
    "    action_list = action_services[action_services['category'] == action_class]\n",
    "\n",
    "    topk_trigger = topk_service(trigger, trigger_list['service'].tolist(), trigger_embedder, 3)\n",
    "    topk_action = topk_service(action, action_list['service'].tolist(), action_embedder, 3)\n",
    "\n",
    "    topk_trigger = get_function(topk_trigger, trigger_functions)\n",
    "    topk_action = get_function(topk_action, action_functions)\n",
    "    topk_recipe = get_topk_recipe(row['generated'], get_combinations(topk_trigger, topk_action), trigger_embedder, action_embedder, 5)\n",
    "\n",
    "    if not topk_recipe:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        continue\n",
    "\n",
    "    temp_df = pd.DataFrame({'top': [topk_recipe[0][1]], 'output': [row['output']]})\n",
    "    output_df = pd.concat([output_df, temp_df], ignore_index=True)\n",
    "    output_df.to_csv('../../error_analysis/noisy.csv', index=False)\n",
    "\n",
    "    if topk_recipe[0][1] == row['output']:\n",
    "        exact_match += 1\n",
    "        \n",
    "    mrr_3 += compute_mrr(topk_recipe, row['output'], 3)\n",
    "    mrr_5 += compute_mrr(topk_recipe, row['output'], 5)\n",
    "\n",
    "    pbar.set_postfix(exact_match=exact_match/(i+1), mrr_3=mrr_3/(i+1), mrr_5=mrr_5/(i+1))\n",
    "\n",
    "output_df.to_csv('../../error_analysis/noisy_final.csv', index=False)"
   ],
   "id": "57acbd8769ad96f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('CRG NOISY')\n",
    "print('Exact Match:', exact_match / len(noisy_generated_crg_set))\n",
    "print('MRR@3:', mrr_3 / len(noisy_generated_crg_set))\n",
    "print('MRR@5:', mrr_5 / len(noisy_generated_crg_set))"
   ],
   "id": "9a4ccae4cac96bd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exact_match = 0\n",
    "mrr_3 = 0.0\n",
    "mrr_5 = 0.0\n",
    "verbose = False\n",
    "pbar =  tqdm.tqdm(gold_generated_crg_set.iterrows(), total=len(gold_generated_crg_set), desc=\"Processing Rows\")\n",
    "\n",
    "output_df = pd.DataFrame(columns=['top','output'])\n",
    "\n",
    "for i, row in pbar:\n",
    "    if row['generated'] == row['output']:\n",
    "        temp_df = pd.DataFrame({'top': [row['generated']], 'output': [row['output']]})\n",
    "        output_df = pd.concat([output_df, temp_df], ignore_index=True)\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        trigger, action = row['generated'].split('THEN', 1)\n",
    "        trigger = trigger.replace('IF','').strip()\n",
    "        action = action.strip()\n",
    "    except:\n",
    "        trigger = row['generated']\n",
    "        action = row['generated']\n",
    "        \n",
    "    trigger_class = classify_text(trigger, trigger_classifier, trigger_embedder)\n",
    "    action_class = classify_text(action, action_classifier, action_embedder)\n",
    "    \n",
    "    trigger_list = trigger_services[trigger_services['category'] == trigger_class]\n",
    "    action_list = action_services[action_services['category'] == action_class]\n",
    "    topk_trigger = topk_service(trigger, trigger_list['service'].tolist(), trigger_embedder, 3)\n",
    "    topk_action = topk_service(action, action_list['service'].tolist(), action_embedder, 3)\n",
    "    topk_trigger = get_function(topk_trigger, trigger_functions)\n",
    "    topk_action = get_function(topk_action, action_functions)\n",
    "    topk_recipe = get_topk_recipe(row['generated'], get_combinations(topk_trigger, topk_action), trigger_embedder, action_embedder, 5)\n",
    "\n",
    "    if not topk_recipe:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        continue\n",
    "\n",
    "    temp_df = pd.DataFrame({'top': [topk_recipe[0][1]], 'output': [row['output']]})\n",
    "    output_df = pd.concat([output_df, temp_df], ignore_index=True)\n",
    "    output_df.to_csv('../../error_analysis/gold.csv', index=False)\n",
    "\n",
    "    if topk_recipe[0][1] == row['output']:\n",
    "        exact_match += 1\n",
    "        \n",
    "    mrr_3 += compute_mrr(topk_recipe, row['output'], 3)\n",
    "    mrr_5 += compute_mrr(topk_recipe, row['output'], 5)\n",
    "\n",
    "    pbar.set_postfix(exact_match=exact_match/(i+1), mrr_3=mrr_3/(i+1), mrr_5=mrr_5/(i+1))\n",
    "\n",
    "output_df.to_csv('../../error_analysis/gold_final.csv', index=False)"
   ],
   "id": "fde9a3a02317ea63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('CRG GOLD')\n",
    "print('Exact Match:', exact_match / len(gold_generated_crg_set))\n",
    "print('MRR@3:', mrr_3 / len(gold_generated_crg_set))\n",
    "print('MRR@5:', mrr_5 / len(gold_generated_crg_set))"
   ],
   "id": "38915a44b209df0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exact_match = 0\n",
    "mrr_3 = 0.0\n",
    "mrr_5 = 0.0\n",
    "verbose = False\n",
    "pbar =  tqdm.tqdm(zip(gold_generated_icg_trigger_set.iterrows(), gold_generated_icg_action_set.iterrows()), total=len(gold_generated_icg_trigger_set), desc=\"Processing Rows\")\n",
    "counter_split = 0\n",
    "counter_eq = 0\n",
    "for (i, t_row), (j, a_row) in pbar:\n",
    "    try:\n",
    "        trigger = t_row['generated'].replace('TRIGGER SERVICE: ', '').strip().replace(', TRIGGER EVENT: ', ' ')\n",
    "        action = a_row['generated'].replace('ACTION SERVICE: ', '').strip().replace(', ACTION EVENT: ', ' ')\n",
    "    except:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        counter_split += 1\n",
    "        continue\n",
    "        \n",
    "    generated = 'IF ' + str(trigger) + ' THEN ' + str(action)\n",
    "    \n",
    "    if generated == gold_generated_crg_set.iloc[i]['output']:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        counter_eq += 1\n",
    "        continue\n",
    "        \n",
    "      \n",
    "    trigger_class = classify_text(trigger, trigger_classifier, trigger_embedder)\n",
    "    action_class = classify_text(action, action_classifier, action_embedder)\n",
    "    trigger_list = trigger_services[trigger_services['category'] == trigger_class]\n",
    "    action_list = action_services[action_services['category'] == action_class]\n",
    "    topk_trigger = topk_service(trigger, trigger_list['service'].tolist(), trigger_embedder, 3)\n",
    "    topk_action = topk_service(action, action_list['service'].tolist(), action_embedder, 3)\n",
    "    topk_trigger = get_function(topk_trigger, trigger_functions)\n",
    "    topk_action = get_function(topk_action, action_functions)\n",
    "    topk_recipe = get_topk_recipe(generated, get_combinations(topk_trigger, topk_action), trigger_embedder, action_embedder, 5)\n",
    "\n",
    "    if not topk_recipe:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        continue\n",
    "        \n",
    "    if topk_recipe[0][1] == gold_generated_crg_set.iloc[i]['output']:\n",
    "        exact_match += 1\n",
    "        \n",
    "    mrr_3 += compute_mrr(topk_recipe, gold_generated_crg_set.iloc[i]['output'], 3)\n",
    "    mrr_5 += compute_mrr(topk_recipe, gold_generated_crg_set.iloc[i]['output'], 5)\n",
    "    \n",
    "    pbar.set_postfix(exact_match=exact_match/(i+1), mrr_3=mrr_3/(i+1), mrr_5=mrr_5/(i+1), counter_eq=counter_eq)"
   ],
   "id": "cff4324b1f60565d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('ICG GOLD')\n",
    "print('Exact Match:', exact_match / len(gold_generated_crg_set))\n",
    "print('MRR@3:', mrr_3 / len(gold_generated_crg_set))\n",
    "print('MRR@5:', mrr_5 / len(gold_generated_crg_set))"
   ],
   "id": "2fb73a6456a73daf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exact_match = 0\n",
    "mrr_3 = 0.0\n",
    "mrr_5 = 0.0\n",
    "verbose = False\n",
    "pbar =  tqdm.tqdm(zip(noisy_generated_icg_trigger_set.iterrows(), noisy_generated_icg_action_set.iterrows()), total=len(noisy_generated_crg_set), desc=\"Processing Rows\")\n",
    "\n",
    "counter_split = 0\n",
    "counter_eq = 0\n",
    "for (i, t_row), (j, a_row) in pbar:\n",
    "    try:\n",
    "        trigger = t_row['generated'].replace('TRIGGER SERVICE: ', '').strip().replace(', TRIGGER EVENT: ', ' ')\n",
    "        action = a_row['generated'].replace('ACTION SERVICE: ', '').strip().replace(', ACTION EVENT: ', ' ')\n",
    "    except:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        counter_split += 1\n",
    "        continue\n",
    "        \n",
    "    generated = 'IF ' + str(trigger) + ' THEN ' + str(action)\n",
    "    \n",
    "    if generated == noisy_generated_crg_set.iloc[i]['output']:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        counter_eq += 1\n",
    "        continue\n",
    "    \n",
    "    trigger_class = classify_text(trigger, trigger_classifier, trigger_embedder)\n",
    "    action_class = classify_text(action, action_classifier, action_embedder)\n",
    "    \n",
    "    trigger_list = trigger_services[trigger_services['category'] == trigger_class]\n",
    "    action_list = action_services[action_services['category'] == action_class]\n",
    "    topk_trigger = topk_service(trigger, trigger_list['service'].tolist(), trigger_embedder, 3)\n",
    "    topk_action = topk_service(action, action_list['service'].tolist(), action_embedder, 3)\n",
    "    topk_trigger = get_function(topk_trigger, trigger_functions)\n",
    "    topk_action = get_function(topk_action, action_functions)\n",
    "    topk_recipe = get_topk_recipe(generated, get_combinations(topk_trigger, topk_action), trigger_embedder, action_embedder, 5)\n",
    "\n",
    "    if not topk_recipe:\n",
    "        exact_match += 1\n",
    "        mrr_3 += 1\n",
    "        mrr_5 += 1\n",
    "        continue\n",
    "          \n",
    "    if topk_recipe[0][1] == noisy_generated_crg_set.iloc[i]['output']:\n",
    "        exact_match += 1\n",
    "        \n",
    "    mrr_3 += compute_mrr(topk_recipe, noisy_generated_crg_set.iloc[i]['output'], 3)\n",
    "    mrr_5 += compute_mrr(topk_recipe, noisy_generated_crg_set.iloc[i]['output'], 5)\n",
    "\n",
    "        \n",
    "    pbar.set_postfix(exact_match=exact_match/(i+1), mrr_3=mrr_3/(i+1), mrr_5=mrr_5/(i+1))"
   ],
   "id": "76e13bee5ce53746",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('ICG NOISY')\n",
    "print('Exact Match:', exact_match / len(noisy_generated_crg_set))\n",
    "print('MRR@3:', mrr_3 / len(noisy_generated_crg_set))\n",
    "print('MRR@5:', mrr_5 / len(noisy_generated_crg_set))"
   ],
   "id": "cef9b710b842e94a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "648fcff75afb28de",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
